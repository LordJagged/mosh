use crate::objects::Object;
use crate::gc::Gc;
use crate::lexer;
use crate::reader_util::ReadError;
use crate::reader_util;

grammar(gc: &mut Box<Gc>);

// R7RS small 7.1.2. External representations
pub Datum: Object = {
    SimpleDatum,
    CompoundDataum,
    "#;" Datum <datum: Datum> => datum,
}

CompoundDataum: Object = {
    List,
    Vector,
    Abbreviation,
}

SimpleDatum: Object = {
    Boolean,
    ByteVector,
    Character,
    Number,
    Regexp,
    String,
    Symbol,
}

List: Object = {
    "(" <objects: Datum *> ")" => gc.listn(&objects),
    "(" <objects: Datum *> "#;" Datum ")" => gc.listn(&objects),
    // TODO: There should be a better way to skip datum comment.
    "(" <objects: Datum *> "#;" Datum "#;" Datum ")" => gc.listn(&objects),
    "(" <objects: Datum *> "#;" Datum "#;" Datum "#;" Datum ")" => gc.listn(&objects),
    "(" <objects: Datum +> "." <last: Datum> "#;" Datum ")" => gc.dot_pair(&objects, last),
    "(" <objects: Datum +> "." <last: Datum> ")" => gc.dot_pair(&objects, last),
}

ByteVector: Object = {
    "#u8(" <objects: Datum *> ")" => gc.new_bytevector(&objects),
}

Vector: Object = {
    "#(" <objects: Datum *> ")" => gc.new_vector(&objects),
}

Abbreviation: Object = {
    "'" <datum: Datum> => {
        let quote = gc.symbol_intern("quote");
        gc.list2(quote, datum)
    },
    "`" <datum: Datum> => {
        let quote = gc.symbol_intern("quasiquote");
        gc.list2(quote, datum)
    },
    "," <datum: Datum> => {
        let quote = gc.symbol_intern("unquote");
        gc.list2(quote, datum)
    },
    ",@" <datum: Datum> => {
        let quote = gc.symbol_intern("unquote-splicing");
        gc.list2(quote, datum)
    },
    "#'" <datum: Datum> => {
        let quote = gc.symbol_intern("syntax");
        gc.list2(quote, datum)
    },
    "#`" <datum: Datum> => {
        let quote = gc.symbol_intern("quasisyntax");
        gc.list2(quote, datum)
    },
    "#," <datum: Datum> => {
        let quote = gc.symbol_intern("unsyntax");
        gc.list2(quote, datum)
    },
    "#@" <datum: Datum> => {
        let quote = gc.symbol_intern("unsyntaxsplicing");
        gc.list2(quote, datum)
    },
}

Regexp: Object = {
    // todo
    "regexp" => gc.new_string(&<>),
}


String: Object = {
    "string" => gc.new_string(&<>),
}

Character: Object = {
    "character" => Object::Char(<>),
}


Symbol: Object = {
    "identifier" => {
        gc.symbol_intern(&reader_util::read_symbol(&<>))
    }
}

Number: Object = {
    <s: "number10"> =>? reader_util::read_number(gc, &s),
    <s: "number8"> =>? reader_util::read_number(gc, &s),
    <s: "number2"> =>? reader_util::read_number(gc, &s),    
    <s: "number16"> =>? reader_util::read_number(gc, &s),
}

Boolean: Object = {
    "true" => Object::True,
    "false" => Object::False,
}

extern {
    type Location = usize;
    type Error = ReadError;

    enum lexer::Token {
        "'" => lexer::Token::AbbrevQuote,
        "`" => lexer::Token::AbbrevQuasiquote,
        "," => lexer::Token::AbbrevUnquote,
        ",@" => lexer::Token::AbbrevUnquoteSplicing,
        "#'" => lexer::Token::AbbrevSyntax,
        "#`" => lexer::Token::AbbrevQuasisyntax,
        "#," => lexer::Token::AbbrevUnsyntax,
        "#@" => lexer::Token::AbbrevUnsyntaxSplicing,
        "#;" => lexer::Token::DatumComment,
        "#u8(" => lexer::Token::ByteVectorStart,
        "." => lexer::Token::Dot,
        "true" => lexer::Token::True,
        "false" => lexer::Token::False,
        "(" => lexer::Token::LeftParen,
        ")" => lexer::Token::RightParen,
        ")" => lexer::Token::RightParen,
        "#(" => lexer::Token::VectorStart,
        "character" => lexer::Token::Character { value: <char> },
        "identifier" => lexer::Token::Identifier { value: <String> },
        "number10" => lexer::Token::Number10 { value: <String> },
        "number8" => lexer::Token::Number8 { value: <String> },
        "number2" => lexer::Token::Number2 { value: <String> },        
        "number16" => lexer::Token::Number16 { value: <String> },
        "regexp" => lexer::Token::Regexp { value: <String> },
        "string" => lexer::Token::String { value: <String> },
    }
}