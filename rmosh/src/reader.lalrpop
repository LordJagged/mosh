use crate::objects::Object;
use crate::gc::Gc;
use crate::lexer;
use crate::ports;
use crate::number_reader::NumberParser;
use crate::number_lexer::NumberLexer;

grammar(gc: &mut Box<Gc>);

// R7RS small 7.1.2. External representations
pub Datum: Object = {
    SimpleDatum,
    CompoundDataum,
    "#;" Datum <datum: Datum> => datum,
}

CompoundDataum: Object = {
    List,
    Vector,
    Abbreviation,
}

SimpleDatum: Object = {
    Boolean,
    ByteVector,
    Character,
    Number,
    Regexp,
    String,
    Symbol,
}

List: Object = {
    "(" <objects: Datum *> ")" => gc.listn(&objects),
    "(" <objects: Datum *> "#;" Datum ")" => gc.listn(&objects),
    // TODO: There should be a better way to skip datum comment.    
    "(" <objects: Datum *> "#;" Datum "#;" Datum ")" => gc.listn(&objects),  
    "(" <objects: Datum *> "#;" Datum "#;" Datum "#;" Datum ")" => gc.listn(&objects),        
    "(" <objects: Datum +> "." <last: Datum> "#;" Datum ")" => gc.dot_pair(&objects, last),    
    "(" <objects: Datum +> "." <last: Datum> ")" => gc.dot_pair(&objects, last),
}

ByteVector: Object = {
    "#u8(" <objects: Datum *> ")" => gc.new_bytevector(&objects),
}

Vector: Object = {
    "#(" <objects: Datum *> ")" => gc.new_vector(&objects),
}

Abbreviation: Object = {
    "'" <datum: Datum> => {
        let quote = gc.symbol_intern("quote");
        gc.list2(quote, datum)
    },
    "`" <datum: Datum> => {
        let quote = gc.symbol_intern("quasiquote");
        gc.list2(quote, datum)
    },
    "," <datum: Datum> => {
        let quote = gc.symbol_intern("unquote");
        gc.list2(quote, datum)
    },
    ",@" <datum: Datum> => {
        let quote = gc.symbol_intern("unquote-splicing");
        gc.list2(quote, datum)
    },
    "#'" <datum: Datum> => {
        let quote = gc.symbol_intern("syntax");
        gc.list2(quote, datum)
    },
    "#`" <datum: Datum> => {
        let quote = gc.symbol_intern("quasisyntax");
        gc.list2(quote, datum)
    },
    "#," <datum: Datum> => {
        let quote = gc.symbol_intern("unsyntax");
        gc.list2(quote, datum)
    },
    "#@" <datum: Datum> => {
        let quote = gc.symbol_intern("unsyntaxsplicing");
        gc.list2(quote, datum)
    },
}

Regexp: Object = {
    // todo
    "regexp" => gc.new_string(&<>),
}


String: Object = {
    "string" => gc.new_string(&<>),
}

Character: Object = {
    "character" => Object::Char(<>),
}


Symbol: Object = {
    "identifier" => {
        gc.symbol_intern(&ports::read_symbol(&<>))
    }
}

Number: Object = {
    <s: "number10"> =>? {
        //println!("NUMBER parse {}", s);
        let mut chars: Vec<char> = s.chars().collect();
        chars.push('\0');
        NumberParser::new().parse(gc, NumberLexer::new(&chars))
    },
    <s: "number16"> => {
        // #x123A => 123A
        if s.chars().nth(0) == Some('#') {
            match isize::from_str_radix(&s[2..], 16) {
                Ok(n) => Object::Fixnum(n),
                Err(e) => {
                        panic!("Number parse error: {} in <{}>", e, s)
                }                
            }
        } else {
            panic!("number16 parse error {}", s)
        }
    }    
}

Boolean: Object = {
    "true" => Object::True,
    "false" => Object::False,
}

extern {
    type Location = usize;
    type Error = ports::ReadError;

    enum lexer::Token {
        "'" => lexer::Token::AbbrevQuote,
        "`" => lexer::Token::AbbrevQuasiquote,
        "," => lexer::Token::AbbrevUnquote,
        ",@" => lexer::Token::AbbrevUnquoteSplicing,
        "#'" => lexer::Token::AbbrevSyntax,
        "#`" => lexer::Token::AbbrevQuasisyntax,
        "#," => lexer::Token::AbbrevUnsyntax,
        "#@" => lexer::Token::AbbrevUnsyntaxSplicing,
        "#;" => lexer::Token::DatumComment,
        "#u8(" => lexer::Token::ByteVectorStart,
        "." => lexer::Token::Dot,
        "true" => lexer::Token::True,
        "false" => lexer::Token::False,
        "(" => lexer::Token::LeftParen,
        ")" => lexer::Token::RightParen,
        ")" => lexer::Token::RightParen,
        "#(" => lexer::Token::VectorStart,
        "character" => lexer::Token::Character { value: <char> },
        "identifier" => lexer::Token::Identifier { value: <String> },
        "number10" => lexer::Token::Number10 { value: <String> },
        "number16" => lexer::Token::Number16 { value: <String> },        
        "regexp" => lexer::Token::Regexp { value: <String> },
        "string" => lexer::Token::String { value: <String> },
    }
}